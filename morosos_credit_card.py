# -*- coding: utf-8 -*-
"""Morosos_credit_card.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eCcnoTEeWPvrtfQQTNob1rAWWTMYx2Ek
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.preprocessing import OneHotEncoder, StandardScaler

import xgboost as xgb
from xgboost import XGBClassifier

df = pd.read_csv('UCI_Credit_Card.csv')
df.head()

df['SEX'].plot(kind='hist', bins=20, title='SEX') # Access the 'SEX' column from the DataFrame 'df'
plt.gca().spines[['top', 'right',]].set_visible(False)

plt.subplots(figsize=(30,20))
sns.heatmap(df.corr(), annot=True)
plt.show()

df['LIMIT_BAL'].plot(kind='hist', bins=20, title='LIMIT_BAL')
plt.gca().spines[['top', 'right',]].set_visible(False)

df.describe()

df.drop(columns=['ID'], axis=1)

df.dropna().mean()

X = df[['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3','PAY_4','PAY_5','PAY_6']]  # Características
y = df['default.payment.next.month']  # Variable objetivo
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)

print('Numero de muestras en y:', np.bincount(y))
print('Numero de muestras en y_train:', np.bincount(y_train))
print('Numero de muestras en y_test:', np.bincount(y_test))

encoder = StandardScaler()
encoder.fit(X_train)

X_train = encoder.transform(X_train)
X_test = encoder.transform(X_test)

#encoder.fit(df[['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3','PAY_4','PAY_5','PAY_6', 'default.payment.next.month']]) # Ajusta el encoder a las columnas categóricas

rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_features='sqrt', criterion='gini')
rf_model.fit(X_train, y_train)

rf_model.feature_importances_

y_pred = rf_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(classification_report(y_test, y_pred))  # Nota: y_test primero, luego y_pred
print(confusion_matrix(y_test, y_pred))  # Nota: y_test primero, luego y_pred
print('\nAccuracy Score for model: ', accuracy_score(y_test, y_pred))  # Nota: y_test primero, luego y_pred
print(f'Accuracy: {accuracy}')

# Define el modelo
# Cambia el nombre de la variable a algo diferente de xgb
xgb_classifier = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Entrena el modelo
xgb_classifier.fit(X_train, y_train)

print(xgb_classifier)
# Si quieres imprimir la información del modelo, usa print(xgb_classifier)

y_pred = xgb_classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(f'Accuracy: {accuracy}')

def predecir(input_df):
    return xgb_classifier.predict(input_df)
